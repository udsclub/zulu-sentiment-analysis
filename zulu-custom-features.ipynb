{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from textblob import TextBlob, Word\n",
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data import\n",
    "rt = pd.read_csv('reviews_rt_all.csv', sep = '|')\n",
    "imdb = pd.read_csv('imdb_small.csv', sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split RT and IMDB datasets seapretely\n",
    "X_train_rt, X_test_rt, y_train_rt, y_test_rt = train_test_split(rt.text, rt.label, test_size=0.2, random_state=42, stratify=rt.label)\n",
    "X_train_imdb, X_test_imdb, y_train_imdb, y_test_imdb = train_test_split(imdb.text, imdb.label, test_size=0.2, random_state=42, stratify=imdb.label)\n",
    "\n",
    "# Then concatenate\n",
    "X_train = pd.concat([X_train_rt, X_train_imdb])\n",
    "X_test = pd.concat([X_test_rt, X_test_imdb])\n",
    "y_train = pd.concat([y_train_rt, y_train_imdb])\n",
    "y_test = pd.concat([y_test_rt, y_test_imdb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Take the last 22 words from each review in the train set\n",
    "X_train = X_train.str.split().apply(lambda x:  ' '.join(x for x in x[-22:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stopwords\n",
    "STOPWORDS = ['by','does', 'was', 'were', 'the', 'of', 'end', 'and', 'is']    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE ENGINEERING (CUSTOM FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 94 µs, sys: 0 ns, total: 94 µs\n",
      "Wall time: 98.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import re\n",
    "\n",
    "def get_rate(s):\n",
    "    candidates = re.findall(r'(\\d{1,3}[\\\\|/]{1}\\d{1,2})', s)\n",
    "    rates = []\n",
    "    for c in candidates:\n",
    "        try:\n",
    "            rates.append(eval(c))\n",
    "        except SyntaxError:\n",
    "            pass\n",
    "        except ZeroDivisionError:\n",
    "            return 0\n",
    "    return np.median(rates)\n",
    "\n",
    "# regular expression to split review on sentences\n",
    "sentence_splitter = re.compile('(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<![A-Z]\\.)(?<=\\!|\\?|\\.)\\s')\n",
    "\n",
    "# lists of positive/negative smiles\n",
    "positive_smiles = set([\n",
    "\":‑)\",\":)\",\":-]\",\":]\",\":-3\",\":3\",\":->\",\":>\",\"8-)\",\"8)\",\":-}\",\":}\",\":o)\",\":c)\",\":^)\",\"=]\",\"=)\",\":‑D\",\":D\",\"8‑D\",\"8D\",\n",
    "\"x‑D\",\"xD\",\"X‑D\",\"XD\",\"=D\",\"=3\",\"B^D\",\":-))\",\";‑)\",\";)\",\"*-)\",\"*)\",\";‑]\",\";]\",\";^)\",\":‑,\",\";D\",\":‑P\",\":P\",\"X‑P\",\"XP\",\n",
    "\"x‑p\",\"xp\",\":‑p\",\":p\",\":‑Þ\",\":Þ\",\":‑þ\",\":þ\",\":‑b\",\":b\",\"d:\",\"=p\",\">:P\", \":'‑)\", \":')\",  \":-*\", \":*\", \":×\"\n",
    "])\n",
    "negative_smiles = set([\n",
    "\":‑(\",\":(\",\":‑c\",\":c\",\":‑<\",\":<\",\":‑[\",\":[\",\":-||\",\">:[\",\":{\",\":@\",\">:(\",\"D‑':\",\"D:<\",\"D:\",\"D8\",\"D;\",\"D=\",\"DX\",\":‑/\",\n",
    "\":/\",\":‑.\",'>:\\\\', \">:/\", \":\\\\\", \"=/\" ,\"=\\\\\", \":L\", \"=L\",\":S\",\":‑|\",\":|\",\"|‑O\",\"<:‑|\"\n",
    "])\n",
    "\n",
    "# pattern to catch SUCH WORDS and ignore SuCH :)\n",
    "uppercase_pattern = re.compile(r'(\\b[0-9]*[A-Z]+[0-9]*[A-Z]{1,}[0-9]*\\b)')\n",
    "\n",
    "# contrast conjugations\n",
    "contrast_conj = set([\n",
    "'alternatively','anyway','but','by contrast','differ from','elsewhere','even so','however','in contrast','in fact',\n",
    "'in other respects','in spite of','in that respect','instead','nevertheless','on the contrary','on the other hand',\n",
    "'rather','though','whereas','yet'])\n",
    "\n",
    "# to get review \"purity\" ~ same sentiment over review (~1) or not (~0)\n",
    "def purity(sentences):\n",
    "    polarities = np.array([TextBlob(x).sentiment.polarity for x in sentences])\n",
    "    return polarities.sum() / np.abs(polarities).sum()\n",
    "\n",
    "# feature engineering ^-^\n",
    "def get_custom_features(text):\n",
    "    # assume text = pd.Series with review text\n",
    "    print('extracting custom features...')\n",
    "    tdf = pd.DataFrame()\n",
    "    tdf['text'] = text \n",
    "    tdf['sentences'] = tdf.text.apply(lambda s: re.split(sentence_splitter, s)) # split to sentences\n",
    "    \n",
    "    #tdf['sentence_cnt'] = tdf['sentences'].apply(len) # feature 1 - (sentence count)\n",
    "    #tdf['exclamation_cnt'] = tdf.text.str.count('\\!') # feature 2 - (exclamation mark count)\n",
    "    #tdf['question_cnt'] = tdf.text.str.count('\\?') # feature 3 - (question mark count)\n",
    "    \n",
    "    # feature 4 - totally uppercase words (like HOLY JESUS!)\n",
    "    #tdf['upper_word_cnt'] = tdf.text.apply(lambda s: len(re.findall(uppercase_pattern, s)))\n",
    "    \n",
    "    # try to extract rating :) like \"great film. 9/10\" will yield 0.9\n",
    "    #tdf['rating'] = tdf['text'].apply(get_rate).fillna(-1) # feature 5 - rating (if found in review)\n",
    "\n",
    "    # try to extract smiles and count positive/negative smiles per review (features 6,7)\n",
    "    tdf['positive_smiles'] = tdf.text.apply(lambda s: len([x for x in s.split() if x in positive_smiles]))\n",
    "    #tdf['negative_smiles'] = tdf.text.apply(lambda s: len([x for x in s.split() if x in negative_smiles]))\n",
    "    \n",
    "    # not so informative, but still\n",
    "    #tdf['contrast_conj_cnt'] = tdf.text.apply(lambda s: len([c for c in contrast_conj if c in s]))\n",
    "    \n",
    "    # feature 8 (polarity of 1st sentence)\n",
    "    #tdf['polarity_1st_sent'] = tdf.sentences.apply(lambda s: TextBlob(s[0]).sentiment.polarity)\n",
    "    # feature 9 (subjectivity of 1st sentence)\n",
    "    #tdf['subjectivity_1st_sent'] = tdf.sentences.apply(lambda s: TextBlob(s[0]).sentiment.subjectivity)\n",
    "    # feature 10 (polarity of last sentence)\n",
    "    #tdf['polarity_last_sent'] = tdf.sentences.apply(lambda s: TextBlob(s[-1]).sentiment.polarity)\n",
    "    # feature 11 (subjectivity of last sentence)\n",
    "    #tdf['subjectivity_last_sent'] = tdf.sentences.apply(lambda s: TextBlob(s[-1]).sentiment.subjectivity)\n",
    "    # feature 12 (subjectivity of review itself)\n",
    "    #tdf['polarity'] = tdf.text.apply(lambda s: TextBlob(s[-1]).sentiment.polarity)\n",
    "    # feature 13 (\"purity\" of review, |sum(sentence polarity) / sum(|sentence polarity|))|, ~ 1 is better, ~ 0 -> mixed\n",
    "    #tdf['purity'] = tdf.sentences.apply(purity)\n",
    "    #tdf['purity'].fillna(0, inplace=True)\n",
    "    \n",
    "    return csr_matrix(tdf[tdf.columns[2:]].values) # to get sparse format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FEATURE EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a list of data extractors/transformers\n",
    "# (format = [('ft1_name', ft1_object), ('ft2_name', ft2_object), ...])\n",
    "\n",
    "extraction_list = []\n",
    "\n",
    "# 1. custom features\n",
    "extraction_list.append(['custom_features', \n",
    "                             FunctionTransformer(func=get_custom_features,\n",
    "                                                 validate=False,\n",
    "                                                 accept_sparse=True\n",
    "                                                )\n",
    "                            ])\n",
    "# 2. simple bag-of-words (vect)\n",
    "extraction_list.append(['vect', \n",
    "                             CountVectorizer(decode_error='ignore',\n",
    "                                             stop_words=STOPWORDS,\n",
    "                                             ngram_range=(1,4),\n",
    "                                             binary = True,\n",
    "                                             lowercase=False\n",
    "                                            )\n",
    "                            ])\n",
    "\n",
    "extractor = FeatureUnion(extraction_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = PassiveAggressiveClassifier(C=0.001, fit_intercept=False, shuffle=False, n_iter = 91, n_jobs = -1)\n",
    "\n",
    "model = Pipeline([('feature_extraction', extractor),\n",
    "                ('clf', clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting custom features...\n",
      "CPU times: user 1min 1s, sys: 3.64 s, total: 1min 5s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "_ = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracting custom features...\n",
      "extracting custom features...\n",
      "extracting custom features...\n",
      "Accuracy RT : 0.808790566222\n",
      "Accuracy IMDB : 0.899\n",
      "Accuracy RT+IMDB : 0.838346111002\n",
      "CPU times: user 38.3 s, sys: 983 ms, total: 39.3 s\n",
      "Wall time: 40.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Compare Validation Accuracy on RT, IMDB and mixed test sets\n",
    "y_pred_rt = model.predict(X_test_rt)\n",
    "y_pred_imdb = model.predict(X_test_imdb)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print (\"Accuracy RT :\", metrics.accuracy_score(y_test_rt, y_pred_rt))\n",
    "print (\"Accuracy IMDB :\", metrics.accuracy_score(y_test_imdb, y_pred_imdb))\n",
    "print (\"Accuracy RT+IMDB :\", metrics.accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
