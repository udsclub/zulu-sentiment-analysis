{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data import\n",
    "rt = pd.read_csv('reviews_rt_all.csv', sep = '|')\n",
    "imdb = pd.read_csv('imdb_small.csv', sep = '|')\n",
    "amazon_test = pd.read_csv('amazon_all_test.csv', sep = '|')\n",
    "amazon_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "#BASE_DIR = '../'\n",
    "TEXT_DATA_DIR = ''#BASE_DIR  + '../data/test'\n",
    "TEXT_DATA_FILE_1 = \"rt-polarity_neg.txt\"\n",
    "TEXT_DATA_FILE_2 = \"rt-polarity_pos.txt\"\n",
    "HEADER = True\n",
    "\n",
    "def load_data():\n",
    "    x = []\n",
    "    y = []\n",
    "    for i in [TEXT_DATA_FILE_1, TEXT_DATA_FILE_2]:\n",
    "        with open(os.path.join(TEXT_DATA_DIR, i), \"r\", encoding='utf-8', errors='ignore') as f:\n",
    "            if HEADER:\n",
    "                _ = next(f)\n",
    "            if i[-7:-4] == \"pos\":\n",
    "                temp_y = 1\n",
    "            else: temp_y = 0\n",
    "            for line in f:\n",
    "                x.append(line.rstrip(\"\\n\"))\n",
    "                y.append(temp_y)\n",
    "\n",
    "    return x, y\n",
    "\n",
    "\n",
    "data, labels = load_data()\n",
    "data = pd.DataFrame({'label': labels, 'text': data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"amazon_all_train.csv\", sep = '|')\n",
    "df.dropna(inplace=True)\n",
    "df_bad = df[df.label == 0]\n",
    "df_good = df[df.label == 1]\n",
    "df_good_new = df_good.sample (n=185376, random_state=42)\n",
    "result = pd.concat([df_good_new, df_bad])\n",
    "result = result.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_am, X_test_am, y_train_am, y_test_am = train_test_split(result.text, result.label, test_size=0.2, random_state=42, stratify=result.label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split RT and IMDB datasets seapretely\n",
    "X_train_rt, X_test_rt, y_train_rt, y_test_rt = train_test_split(rt.text, rt.label, test_size=0.2, random_state=42, stratify=rt.label)\n",
    "X_train_imdb, X_test_imdb, y_train_imdb, y_test_imdb = train_test_split(imdb.text, imdb.label, test_size=0.2, random_state=42, stratify=imdb.label)\n",
    "\n",
    "# Then concatenate\n",
    "X_train = pd.concat([X_train_rt, X_train_imdb])\n",
    "X_test = pd.concat([X_test_rt, X_test_imdb])\n",
    "y_train = pd.concat([y_train_rt, y_train_imdb])\n",
    "y_test = pd.concat([y_test_rt, y_test_imdb])\n",
    "X_train_am = pd.concat([X_train_am, X_train_rt])\n",
    "y_train_am = pd.concat([y_train_am, y_train_rt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Stopwords\n",
    "STOPWORDS = ['by','does', 'was', 'were', 'the', 'of', 'end', 'and', 'is']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvect = CountVectorizer()\n",
    "counts = cvect.fit_transform(X_train_am)\n",
    "\n",
    "classifier = PassiveAggressiveClassifier(C=0.001, fit_intercept = False, shuffle = False, n_iter = 91, n_jobs = -1)\n",
    "pipeline = Pipeline([('vectorizer', CountVectorizer(binary=True,ngram_range=(1,4),stop_words=STOPWORDS)), ('classifier', classifier)])\n",
    "model = pipeline.fit(X=X_train_am, y=y_train_am)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy RT : 0.773639774859\n",
      "F1 RT : 0.773405953611\n",
      "Accuracy Amazon : 0.918692815711\n",
      "F1 Amazon : 0.951080626897\n"
     ]
    }
   ],
   "source": [
    "y_pred_rt_new = model.predict(data.text)\n",
    "y_pred_amazon = model.predict(amazon_test.text)\n",
    "\n",
    "print (\"Accuracy RT :\", metrics.accuracy_score(data.label, y_pred_rt_new))\n",
    "print (\"F1 RT :\", metrics.f1_score(data.label, y_pred_rt_new))\n",
    "\n",
    "print (\"Accuracy Amazon :\", metrics.accuracy_score(amazon_test.label, y_pred_amazon))\n",
    "print (\"F1 Amazon :\", metrics.f1_score(amazon_test.label, y_pred_amazon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joblib.dump(model, 'output_amazon.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
